{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Pandas for software engineering research\n",
    "\n",
    "- **Auhtor**: Felipe Ortega.\n",
    "- **Date**: June 7, 2017.\n",
    "- **Venue**: SATToSE 2017 Workshop.\n",
    "- **Location**: URJC. Madrid.\n",
    "- **Part**: 1 of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is one of the most popular libraries for **Python scientific programming**. In this tutorial, we explore the use of `Pandas` to load, prepare and analyse structured datasets, using the **`DataFrame` data structure** that has become a ubiquitous tool in data science.\n",
    "\n",
    "To follow this tutorial, you should have [**Anaconda Python**](https://www.continuum.io/downloads) installed in your system (64-bit version, probably for Python 3.6). You should also create a new virtual environment with `conda`, either [using the command line](https://conda.io/docs/using/envs.html#create-an-environment) or using [Anaconda Navigator](https://docs.continuum.io/anaconda/navigator/). In this way, you will have a separate virtual space to play with these examples. If you already have a favourite IDE for Python programming, you can [follow the instructions to use Anaconda in your IDE](https://docs.continuum.io/anaconda/ide_integration)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SATToSE 2017 workshop presents a dataset of 250K recent Scratch projects from 100K different authors scraped from the Scratch project repository. You can find this dataset [on GitHub](https://github.com/TUDelftScratchLab/ScratchDataset).\n",
    "\n",
    "Data from Scratch projects are available in different formats, stored in the GitHub repository presented above:\n",
    "* Raw data in [CSV files](https://github.com/TUDelftScratchLab/ScratchDataset/tree/master/Dataset/CSV%20files).\n",
    "* A compressed (gzip) [MySQL dump file](https://github.com/TUDelftScratchLab/ScratchDataset/tree/master/Dataset/mySQL).\n",
    "* A compressed (zip) [SQL server backup file](https://github.com/TUDelftScratchLab/ScratchDataset/tree/master/Dataset/SQL%20Server).\n",
    "\n",
    "In this tutorial, we use the second option and upload all data in a **local MySQL database**, named `Scratch_data`.\n",
    "\n",
    "Once you have created this local database and uploaded the Scratch dataset into it, you can continue following this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Python DB API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, there are several packages that we can use to communicate with popular RDBMS products, such as MySQL/MariaDB or PostgreSQL. An advantage is that many of these packages stick to a standard high-level interface to communicate with any database, defined in [PEP 249 -- Python Database API Specification v2.0](https://www.python.org/dev/peps/pep-0249/). Hence, we can be confident to find the same methods in any of these packages, disregarding of which particular database we need to interact with.\n",
    "\n",
    "There are several Python packages that provide connectivity between Python and MySQL. In [this article from OpenStack](https://wiki.openstack.org/wiki/PyMySQL_evaluation) you can find a nice comparison among some of these alternatives. In essence, all Python connectors for MySQL are divided into native Python connectors (written entirely in pure Python) and wrappers around starndard MySQL connector library written in C. However, **we must be careful** if we aim at **using Python 3**, since **some of the most popular packages are not compatible** with this Python version. You can also consider some of the ORM frameworks in Python to use these libraries, such as [SQLAlchemy](https://www.sqlalchemy.org/).\n",
    "\n",
    "For the sake of simplicity, in this tutorial we use [`PyMySQL`](https://github.com/PyMySQL/PyMySQL), a pure Python MySQL client. Please, bear in mind that this is the most straightforward option for easy installation and maintenance (no external requirements, such as low-level C library package) but, regarding performance, it is probably one of the slowest alternatives available. It is also fully compliant with Python 3${^1}$.\n",
    "\n",
    "${^1}$: *If performance is a major concern for you, then you should probably use one of the options wrapped on top of the low-level C API for MySQL, always watching for compatibility with Python 3 (if needed)*. One example is [mysqlclient-python](https://github.com/PyMySQL/mysqlclient-python)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install PyMySQL, type the following in a command-line where you have activated your virtual environment in Anaconda (in the example below, the virtual environment is `datascience`). In Windows, you can also activate your virtual environment using Anaconda Navigator:\n",
    "\n",
    "```bash\n",
    "$ source ~/anaconda3/bin/activate datascience\n",
    "(datascience)$ pip install PyMySQL\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 DB connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we procceed to connect to our local database and get some data using `PyMySQL`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'p_ID': 10519701, 'total-views': 4.0, 'total-remixes': 0.0}, {'p_ID': 10541430, 'total-views': 2.0, 'total-remixes': 0.0}, {'p_ID': 10942522, 'total-views': 3.0, 'total-remixes': 0.0}, {'p_ID': 11823040, 'total-views': 25.0, 'total-remixes': 0.0}, {'p_ID': 11828235, 'total-views': 1.0, 'total-remixes': 0.0}, {'p_ID': 12030146, 'total-views': 15.0, 'total-remixes': 0.0}, {'p_ID': 12093755, 'total-views': 1.0, 'total-remixes': 0.0}, {'p_ID': 12237615, 'total-views': 4.0, 'total-remixes': 0.0}, {'p_ID': 12256407, 'total-views': 2.0, 'total-remixes': 0.0}, {'p_ID': 12441584, 'total-views': 3.0, 'total-remixes': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "import pymysql.cursors\n",
    "\n",
    "# Get new connection with local MySQL DB\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='jfelipe',\n",
    "                             password='phoenix',\n",
    "                             db='Scratch_data',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        # Read some data\n",
    "        sql = \"\"\"SELECT `p_ID`, `total-views`, `total-remixes`\n",
    "                 FROM `project` LIMIT 10\"\"\"\n",
    "        cursor.execute(sql)\n",
    "        result = cursor.fetchall()\n",
    "        print(result)\n",
    "finally:\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `result` object stores all values returned by the query, whereas the `cursor.description` attribute of the `cursor` object contains metadata about the columns returned by the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('p_ID', 8, None, 20, 20, 0, False),\n",
       " ('total-views', 5, None, 22, 22, 31, True),\n",
       " ('total-remixes', 5, None, 22, 22, 31, True))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cursor description\n",
    "# See: https://www.python.org/dev/peps/pep-0249/#cursor-attributes\n",
    "cursor.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we can start using the specific modules for scientific programming in Python to analyse our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scientific programming with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exist many different modules supporting the complete technology stack for Python scientific programming. Figure 1 below depicts the diagram showing the different components in the stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"scientific-python-28-638.jpg\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Figure 1**: Technology stack in Python scientific programming (source: [Jake VanderPlas](https://staff.washington.edu/jakevdp/), [“The State of the Stack”](https://speakerdeck.com/jakevdp/the-state-of-the-stack-scipy-2015-keynote), keynote in *SciPy 2015*).</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of the core Python interpreter we find a **first layer** of projects providing support for all **basic features**:\n",
    "* **IPython**: Enhnaced interactive interpreter for Python programming, with special emphasis on scientific applications.\n",
    "* **Jupyter**: Web application that enables the creation of interactive notebooks (like this document), implementing (and extending) the principles of [*literate programming*](https://en.wikipedia.org/wiki/Literate_programming). Jupyter notebooks are interactive, and they can be edited and extended to your own needs, facilitating knowledge sharing and management. Currently, Jupyter features support for 40 programming languages, including (besides Python) R, Julia or Scala.\n",
    "* **NumPy**: This is the baseline module for numerical calculations in Python scientific programming. It provides support for working with N-dimensional array objects, fast computations through integration of C/C++ and Fortran code or specialised functions and methods (e.g. Fourier transforms, random numbers or linear algebra).\n",
    "\n",
    "The **second layer** of the Python scientific stack includes several modules that build on top of the first layer to solve more complex but still **fundamental features**:\n",
    "\n",
    "* **SciPy**: This is a library comprising several modules implementing more [complex and specialized scientific operations](https://docs.scipy.org/doc/scipy/reference/), on top of NumPy. For example, we can find support for integration, optimization, signal processing or graph routines.\n",
    "* **Matplotlib**: This is the baseline data visualization service for Python scientific programming.\n",
    "* **Pandas**: A library implementing fundamental data structures and operations to deal with structured datasets (similar to database tables). This is the main component that we use in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond these two first layers, we can find **high-level projects** that tackle more complex tasks. Among these projects, we can highlight:\n",
    "\n",
    "* **StatsModels**: Implementation of statistical models and algorithms.\n",
    "* **Scikit-learn**: Data mining and machine learning algorithms and routines. It also includes standard procedures to define and implement [data pipelines](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
    "* **PyTables**: Support for hierarchical and very large datasets (structured data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will focus on `Pandas` to work with regular data tables. Besides, we will also introduce `Seaborn`, an additional project to make it easier the creation of advanced data visualization graphs from `Pandas` objects. Finally, we will also introduce some cutting-edge projects recently created to undertake the increasingly popular need of processing large datasets on distributed computer infrastructures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Introducing `Pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NumPy` and `SciPy` provide support for low-level programming operations and routines. The [**Pandas**](http://pandas.pydata.org/pandas-docs/stable/) library sits on top of them to provide all principal operations to deal with structured datasets, including data loading, data preparation and cleansing. Pandas also provides familiar data structures and operations for data scientists, such as **Series** for **indexed arrays of values** or the **DataFrame** class for data tables.\n",
    "\n",
    "The name of the Pandas library is derived, in part from **panel data** (pan(el)-da(ta)-s). This term is usually found in econometrics and social sciences to name data tables organized in a way similar to a table in a relational database:\n",
    "\n",
    "* One case for each row.\n",
    "* One variable for each column, defined as a fixed data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantages of using `Pandas` for data cleaning and analytics are working with standard data structures, methods and procedures to work with **structured datasets**, including data from relational databases or labeled data.\n",
    "\n",
    "The main use cases of `Pandas` are:\n",
    "\n",
    "* Working with data tables with columns of different types (but always using the same type for all values in a single column). This is similar to the `data.frame` objects in the R programming language, that in fact inspired the creation of the `DataFrame` class in `Pandas`.\n",
    "* Working with time series data, both regular or irregular, and not necessarily ordered.\n",
    "* Working with matrices, with rows and columns that can be labeled (again, pretty much like in R).\n",
    "* In general, it is adequate for working with most of the datasets that can be found in data science studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among its **main features** we can mention:\n",
    "\n",
    "* Handling missing data.\n",
    "* Mutable size of objects. We can add or delete columns or rows in N-dimensional collections of objects and primitive types.\n",
    "* Explicit data alignment, according to a series of ordered labels (such as integers, strings or timestamps), or totally automatic alignment.\n",
    "* Applying *split-and-combine* operations, similar to the working philosophy of the `dplyr` and `tidyr` libraries in the R programming language.\n",
    "* Powerful and efficient ways for indexing and creating subsets, based on labels or categories.\n",
    "* Joining and integrating datasets (operations like *join* or *union*).\n",
    "* Transforming data tables between *long* and *wide* formats (which is called *reshaping* and *pivoting* in `Pandas` terminology).\n",
    "* Hierarchical labeling of dimensional axes.\n",
    "* Wide variety of I/O functions, facilitating the reading/writing from/to data files in different formats, such as plain text files (CSV/TSV), MS Excel, databases or HDF5.\n",
    "* Support for time series operations, like generating data at regular intervals, sampling frequency conversion, descriptive statistics and linear regression on sliding windows, data shifting and lagging, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Pandas` library documentation presents a succint [10-minute introduction to `Pandas`](http://pandas.pydata.org/pandas-docs/stable/10min.html), with interesting examples to illustrate some of the basic data structures and methods.\n",
    "\n",
    "To start working with `Pandas`, we only need to import the `NumPy` and `Pandas` libraries, following the standard convention in Python scientific programming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version:  1.12.1\n",
      "Pandas version:  0.20.1\n"
     ]
    }
   ],
   "source": [
    "# Check version of both libraries\n",
    "print(\"NumPy version: \", np.__version__)\n",
    "print(\"Pandas version: \", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Series objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main data structures implemented in `Pandas` are the `Series` class and the `DataFrame` class. In this section, we start describing `Series` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Creating `Series` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Series` objects contain a **data vector** (similar to a NumPy array), but they also have **identification labels for each element in the vector**, instead of using a basic integer index to order data. This is an important advantage, since we can reorder values in a `Series` object efficiently (using labels), or we can find values within the series (for a unique label). Furthermore, this data structure is ideal for manage **time series data** (series of values along with the timestamp for each value), as we will see in another section below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`Series` objects](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#series) can be created from different types of input data, described by the `data` argument, such as Python dictionaries, `ndarray` NumPy objects or scalar values.\n",
    "\n",
    "```python\n",
    "my_series = pd.Series(data, index=my_index)\n",
    "```\n",
    "\n",
    "Besides, we must provide an `index` argument, with a vector of labels to identify each of the values within the series. This spawns different use cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a   -0.583969\n",
       "b   -0.074399\n",
       "c   -0.455512\n",
       "d    0.633556\n",
       "e   -0.861814\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If data is an ndarray, then the index vector musth be of the same length\n",
    "series_1 = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a', 'b', 'c', 'd', 'e'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The index attribute stores the vector of labels for the series of values\n",
    "series_1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.58396939, -0.07439888, -0.45551169,  0.63355603, -0.86181351])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The vector of values is stored in the values attribute\n",
    "series_1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.826285\n",
       "1    0.307435\n",
       "2    0.855067\n",
       "3    0.866171\n",
       "4    0.557727\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we do not provide an index vector of labels, then a numerical index is created automatically\n",
    "series_2 = pd.Series(np.random.rand(5))\n",
    "series_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    2.0\n",
       "c    3.0\n",
       "d    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If data is in a Python dictionary, then if we pass a vector of indexes\n",
    "# then indexing labels will be used to take the elements in the dictionary\n",
    "# according to the key of each element, in the same order in which\n",
    "# the labels appear in the vector of indexes\n",
    "\n",
    "# If no index vector is provided, labels are created from the ordered\n",
    "# keys of the dictionary\n",
    "d = {'a': 1., 'b': 2., 'c': 3.0, 'd': 4. }\n",
    "pd.Series(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e    NaN\n",
       "d    4.0\n",
       "c    3.0\n",
       "b    2.0\n",
       "a    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If one of the keys in the vector of indexes is not found as a key\n",
    "# in the dictionary, a NaN value is automatically inserted in that position\n",
    "pd.Series(d, index = ['e', 'd', 'c', 'b', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ordinal\n",
       "0    0.826285\n",
       "1    0.307435\n",
       "2    0.855067\n",
       "3    0.866171\n",
       "4    0.557727\n",
       "Name: Series 2, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also assign a name to the Series object\n",
    "# This is useful when we create multi-dimensional data\n",
    "# structures comprising several Series objects\n",
    "series_2.name = \"Series 2\"\n",
    "series_2.index.name = \"Ordinal\"\n",
    "series_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Indexing objects in `Pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any data structure in `Pandas` can be indexed in 3 different ways:\n",
    "\n",
    "1. Indexing by label: https://pandas.pydata.org/pandas-docs/stable/indexing.html#selection-by-label.\n",
    "2. Indexing by position: https://pandas.pydata.org/pandas-docs/stable/indexing.html#selection-by-position.\n",
    "3. Indexing by *callable*: https://pandas.pydata.org/pandas-docs/stable/indexing.html#selection-by-callable.\n",
    "\n",
    "Hence, we can use any of these options in either `Series` or `DataFrame` objects. An important remark is that we cannot mix different types of selection together in the same indexing expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Indexing `Series` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing operations in `Series` objects are similar to the equivalent options in other languages: using numerical indexes, boolean expressions, etc. In Python, you can also use *slicing* for numerical or label indexes, provided that there is a strict ordering among their values.\n",
    "\n",
    "Additionally, since indexing labels are stored alongside the vector of values in a `Series` object, we can use such labels like in a Python dictionary, to access individual elements (or a group of them). This option has de additional advantage that is very fast (low computational complexity) and the resulting code is quite clear and readable, since we are using meaningful identifiers to access values in the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.58396939323693919"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing with numerical positions, individually or with slicing\n",
    "series_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c   -0.455512\n",
      "d    0.633556\n",
      "e   -0.861814\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(series_1[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a   -0.583969\n",
      "b   -0.074399\n",
      "c   -0.455512\n",
      "d    0.633556\n",
      "e   -0.861814\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(series_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a   -0.583969\n",
       "b   -0.074399\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing with labels\n",
    "series_1[['a', 'b']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a   -0.583969\n",
       "e   -0.861814\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing with boolean expressions\n",
    "series_1[series_1 < -0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ordinal\n",
       "2    0.855067\n",
       "3    0.866171\n",
       "Name: Series 2, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using boolean expression and callable (method median)\n",
    "series_2[series_2 > series_2.median()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pay attention to results in the examples above, we can check that we not only get a subset of values, but also the corresponding subset of indexes corresponding to those values. That is, the *slicing* indexing is applied to both the vector of indexes and the vector of values inside the `Series` object. In this way, we can index without losing any of the special properties of this object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Operations with `Series` objects\n",
    "\n",
    "It is possible to perform arithmetic operations or functions over the values stored in a `Series` object, like we do in other objects in scientific Python programming such as `NumPy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ordinal\n",
       "0   -0.082870\n",
       "1   -0.512247\n",
       "2   -0.068000\n",
       "3   -0.062396\n",
       "4   -0.253578\n",
       "Name: Series 2, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(series_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a   -1.167939\n",
       "b   -0.148798\n",
       "c   -0.911023\n",
       "d    1.267112\n",
       "e   -1.723627\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add up element by element, using the index labels\n",
    "# to match cases in each series\n",
    "series_1 + series_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 `DataFrame` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Pandas` [`DataFrame` class](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe) defines aa data structure to store and process datasets along the same lines of `data.frame` objects in the R programming language. It is a table of values organized such that:\n",
    "\n",
    "* Each row corresponds to an individual case or element in the study.\n",
    "* Each column is a variable in the study. All values in the column must be of the same type.\n",
    "\n",
    "Like in a relational database or a CSV file, if any of the cells in this table is empty we have **missing data** and the \"space\" is explicitly marked. Therefore, this is a case of **structured data**. The resulting table has dimensions $M x N$, where **all rows must be of length $M$** and **all rows must be of length $N$**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Creating `DataFrame` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create `DataFrame` objects from different input data types, including Python lists and dictionaries, `ndarray` objects from `NumPy`, or `Series` and `DataFrame` objects in `Pandas`. In `DataFrame` objects, both rows and columns are labeled. The labels for columns are particularly important, since they identify the variables included in our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collate</th>\n",
       "      <th>gender</th>\n",
       "      <th>group</th>\n",
       "      <th>intake</th>\n",
       "      <th>output</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>55.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>55.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>55.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>54.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>56.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>57.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>57.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collate gender group  intake  output  year\n",
       "0       15      M     A    55.3     1.1  2010\n",
       "1        5      M     A    55.4     1.1  2011\n",
       "2       10      M     A    55.3     1.1  2012\n",
       "3       40      M     A    55.5     1.1  2013\n",
       "4       20      M     A    54.4     1.1  2014\n",
       "5       12      M     B    56.6     1.1  2010\n",
       "6       12      M     B    57.7     1.1  2011\n",
       "7       12      M     B    55.4     1.1  2012\n",
       "8       12      M     B    57.9     1.1  2013\n",
       "9       12      M     B    56.0     1.1  2014"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this example, we illustrate different input formats for each column\n",
    "# If we introduce a single value for any column, it is replicated as many\n",
    "# times as needed to fill in all positions in that column.\n",
    "\n",
    "# Note the fancy formatting for DataFrame output in Jupyter notebooks\n",
    "data_1 = {\n",
    "    'year': [2010, 2011, 2012, 2013, 2014] * 2 ,\n",
    "    'group': ['A'] * 5 + ['B'] * 5,\n",
    "    'intake': (55.3, 55.4, 55.3, 55.5, 54.4, 56.6, 57.7, 55.4, 57.9, 56),\n",
    "    'output': 1.1,\n",
    "    'collate': np.array([15, 5, 10, 40, 20, 12, 12, 12, 12, 12]),\n",
    "    'gender': \"M\"\n",
    "}\n",
    "df_1 = pd.DataFrame(data_1)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important trait of `DataFrame` objects is that all columns must share the same indexes. In fact, `DataFrames` are created by joining `Series` objects, one for each column, and matching the corresponding index vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading data from files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other methods in `Pandas` for reading data from input files:\n",
    "* `read_excel()` (files in  MS Excel format).\n",
    "* `read_html()` (input data in HTML).\n",
    "* `read_json()` (reading data in JSON format).\n",
    "* `read_hdf()` (reading HDF5 data files).\n",
    "* `read_pickle()` (reading Python objects, serialized using `cPickle`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Creating `DataFrame` objects from database queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our example data is stored in the local MySQL database `Scratch_data` that we queried above. Remember that the `result` object stores the values returned by the query and the column names are the first elements of each object returned by `cursor.description`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DataFrame constructor receives a list of dictionaries\n",
    "# as the first argument. In each dictionary, keys identify the\n",
    "# name of the column for the corresponding element.\n",
    "\n",
    "# The columns argument receives a list of labels identifying the\n",
    "# name of each columns. The columns will be created in the\n",
    "# same order in which we arrange the labels of the columns argument\n",
    "col_names = [x[0] for x in cursor.description]\n",
    "project_df = pd.DataFrame(result, columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_ID</th>\n",
       "      <th>total-views</th>\n",
       "      <th>total-remixes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10519701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10541430</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10942522</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11823040</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11828235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       p_ID  total-views  total-remixes\n",
       "0  10519701          4.0            0.0\n",
       "1  10541430          2.0            0.0\n",
       "2  10942522          3.0            0.0\n",
       "3  11823040         25.0            0.0\n",
       "4  11828235          1.0            0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we can use the head() method to inspect the first 5 rows\n",
    "project_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p_ID', 'total-views', 'total-remixes'], dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of columns in DataFrame object\n",
    "project_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10, step=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of row indexes in DataFrame object\n",
    "project_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collate</th>\n",
       "      <th>group</th>\n",
       "      <th>intake</th>\n",
       "      <th>genotype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>A</td>\n",
       "      <td>55.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>55.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>55.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>A</td>\n",
       "      <td>55.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>A</td>\n",
       "      <td>54.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>B</td>\n",
       "      <td>56.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>B</td>\n",
       "      <td>57.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>B</td>\n",
       "      <td>55.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>B</td>\n",
       "      <td>57.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>B</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collate group  intake  genotype\n",
       "0       15     A    55.3       NaN\n",
       "1        5     A    55.4       NaN\n",
       "2       10     A    55.3       NaN\n",
       "3       40     A    55.5       NaN\n",
       "4       20     A    54.4       NaN\n",
       "5       12     B    56.6       NaN\n",
       "6       12     B    57.7       NaN\n",
       "7       12     B    55.4       NaN\n",
       "8       12     B    57.9       NaN\n",
       "9       12     B    56.0       NaN"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame from a subset of columns from\n",
    "# another DataFrame. If there are non-existing columnns referenced\n",
    "# in the columns argument, a new column with that label is created\n",
    "# and all values in that column are filled out with 'NaN' (label for\n",
    "# missing data)\n",
    "df_2 = pd.DataFrame(df_1, columns=['collate', 'group', 'intake', 'genotype'])\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Indexing `DataFrame` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can index subsets of rows or columns. For this, we can use the typical *slicing* syntax in Python with either numeric indexes or labels (if they were previously assigned)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10, step=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector of indexes\n",
    "project_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.05197010e+07,   4.00000000e+00,   0.00000000e+00],\n",
       "       [  1.05414300e+07,   2.00000000e+00,   0.00000000e+00],\n",
       "       [  1.09425220e+07,   3.00000000e+00,   0.00000000e+00],\n",
       "       [  1.18230400e+07,   2.50000000e+01,   0.00000000e+00],\n",
       "       [  1.18282350e+07,   1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.20301460e+07,   1.50000000e+01,   0.00000000e+00],\n",
       "       [  1.20937550e+07,   1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.22376150e+07,   4.00000000e+00,   0.00000000e+00],\n",
       "       [  1.22564070e+07,   2.00000000e+00,   0.00000000e+00],\n",
       "       [  1.24415840e+07,   3.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Values is a bidimensional ndarray (NumPy)\n",
    "project_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(project_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4.0\n",
       "1     2.0\n",
       "2     3.0\n",
       "3    25.0\n",
       "4     1.0\n",
       "5    15.0\n",
       "6     1.0\n",
       "7     4.0\n",
       "8     2.0\n",
       "9     3.0\n",
       "Name: total-views, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing by name of column\n",
    "project_df['total-views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The result is a Series object\n",
    "type(project_df['total-views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.0\n",
       "1    2.0\n",
       "2    3.0\n",
       "Name: total-views, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing with rows and columns\n",
    "project_df[:3]['total-views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.0\n",
       "1    2.0\n",
       "2    3.0\n",
       "Name: total-views, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the same as using the loc() and iloc() methods\n",
    "project_df.iloc[:3].loc[: ,'total-views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10519701\n",
       "1    10541430\n",
       "2    10942522\n",
       "3    11823040\n",
       "4    11828235\n",
       "5    12030146\n",
       "6    12093755\n",
       "7    12237615\n",
       "8    12256407\n",
       "9    12441584\n",
       "Name: p_ID, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yet another way to index is using column labels or row indexes\n",
    "# as attributes of the DataFrame (or Series) object\n",
    "\n",
    "# WARNING: this will not work with labels containing blank spaces or dashes\n",
    "# like some of the columns in our dataset. In those cases, consider\n",
    "# renaming the columns to always use underscores '_'\n",
    "project_df.p_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total-remixes</th>\n",
       "      <th>total-views</th>\n",
       "      <th>p_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10519701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10541430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10942522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11823040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11828235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12030146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12093755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12237615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12256407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12441584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total-remixes  total-views      p_ID\n",
       "0            0.0          4.0  10519701\n",
       "1            0.0          2.0  10541430\n",
       "2            0.0          3.0  10942522\n",
       "3            0.0         25.0  11823040\n",
       "4            0.0          1.0  11828235\n",
       "5            0.0         15.0  12030146\n",
       "6            0.0          1.0  12093755\n",
       "7            0.0          4.0  12237615\n",
       "8            0.0          2.0  12256407\n",
       "9            0.0          3.0  12441584"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use reindexing to create a new object with their\n",
    "# indexes arranged in a different way\n",
    "project_df2 = project_df.reindex(columns=['total-remixes', 'total-views', 'p_ID'])\n",
    "project_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total-remixes</th>\n",
       "      <th>total-views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total-remixes  total-views\n",
       "0            0.0          4.0\n",
       "1            0.0          2.0\n",
       "2            0.0          3.0\n",
       "3            0.0         25.0\n",
       "4            0.0          1.0\n",
       "5            0.0         15.0\n",
       "6            0.0          1.0\n",
       "7            0.0          4.0\n",
       "8            0.0          2.0\n",
       "9            0.0          3.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also drop rows or columns\n",
    "# axis = 0 rows\n",
    "# axis = 1 columns\n",
    "project_df2 = project_df2.drop('p_ID', axis=1)\n",
    "project_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find additional information about this class in the [`DataFrame` documentation](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe) in the `Pandas` project, as well as in the [introduction to Pandas notebook](https://github.com/fonnesbeck/Bios8366/blob/master/notebooks/Section2_1-Introduction-to-Pandas.ipynb) by C. Fonnesbeck (Vanderbilt Univ.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Dealing with time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important data type for `Pandas` is **time series data**. In this kind of structure, we have values associated with dates or timestamp info (sometimes only dates, other times including dates and time), indicating when each datum was collected. With this information we can build series of values along time, ordering them in a chronological fashion.\n",
    "\n",
    "The `Pandas` library offers an [extensive collections of methods and tools to deal with time series data](http://pandas.pydata.org/pandas-docs/stable/timeseries.html), including many functions already present in other packages that have been consolidated in `Pandas`, as a jackknife for these purposes.\n",
    "\n",
    "The first important function of this kind is `date_range`, that lets us generate ranges of labels alongg time from an initial starting point, by specifyinng the interval between equidistant points along time and the number of points to create:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-01-01 00:00:00', '2016-01-01 01:00:00',\n",
       "               '2016-01-01 02:00:00', '2016-01-01 03:00:00',\n",
       "               '2016-01-01 04:00:00'],\n",
       "              dtype='datetime64[ns]', freq='H')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 48 hours since 00:00:00 of January 1, 2016\n",
    "rng = pd.date_range('01/01/2016', periods=48, freq='H')\n",
    "rng[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-01-01 00:00:00    2.620085\n",
       "2016-01-01 01:00:00   -0.930885\n",
       "2016-01-01 02:00:00   -1.243790\n",
       "2016-01-01 03:00:00    0.029398\n",
       "2016-01-01 04:00:00    0.249420\n",
       "Freq: H, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using time range to index `Series` objects, converting them into\n",
    "# time series (time/value pairs)\n",
    "serie_4 = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "serie_4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, there are two basic forms to define a vector of values along time in `Pandas`:\n",
    "\n",
    "* *Timestamps*: data indicating the exact date and time associated with each value point. They are generated with the  `Timestamp` class. Their associated indexes are of class `DatetimeIndex`.\n",
    "* *Time spans*: they represent a single time interval, in which we indicate the starting point and the sampling frequency among the points comprising the series. The associated index is of class `PeriodIndex`.\n",
    "\n",
    "Let's see some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "ts_1 = pd.Timestamp(datetime(2015, 1, 1))\n",
    "ts_2 = pd.Timestamp(np.datetime64('2016-06-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2015-01-01 00:00:00')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-06-01 00:00:00')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('517 days 00:00:00')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can directly perform arithmetic operations on the time axis\n",
    "# like substracting Timestamps, resulting in a Timedelta object\n",
    "ts_2 - ts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2011-01', 'M')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_1 = pd.Period('2011-01')\n",
    "period_2 = pd.Period('2011-01-01')\n",
    "period_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2011-01-01', 'D')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-05-01    0.772749\n",
       "2016-05-02   -1.011647\n",
       "2016-05-03    0.072712\n",
       "dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using them with `Series` object to create time series data\n",
    "dates = [pd.Timestamp('2016-05-01'), pd.Timestamp('2016-05-02'), pd.Timestamp('2016-05-03')]\n",
    "time_series_1 = pd.Series(np.random.randn(3), index=dates)\n",
    "time_series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.datetimes.DatetimeIndex"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(time_series_1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-05-01', '2016-05-02', '2016-05-03'], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_1.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Data pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some core libraries for Python scientific programming are being heavily influenced by good practices imported from other programming languages, most notably R. In the R programming language, the recent introduction of the `dplyr` and `tidyr` packages has led to a revolution in the definition and implementation of data proccessing and transformation pipelines. We can now define this sort of workflows explicitly on software code, taking advantage of other new packages like `magrittr`, which provides the `%>%` (*forward pipe*) operator. In this way, the syntax to define data processing workflows becomes even more readable and maintainable for programmers.\n",
    "\n",
    "In Python, `Pandas` has not stayed unaware of this influence that is starting to become quite popular in data science. Operations like [group by](http://pandas.pydata.org/pandas-docs/stable/groupby.html) (following the *split-apply-combine* paradigm), [*merge* and *join*](http://pandas.pydata.org/pandas-docs/stable/merging.html), along with [transforming between *long* and *wide* data formats](http://pandas.pydata.org/pandas-docs/stable/reshaping.html) are fully supported through an ample collection of tools and methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most notably, the **concatenation of operations and callables** (similar to the one available in R through the `%>%` operator) can be achieved in `Pandas` with the  [**`pipe()` method**](http://pandas.pydata.org/pandas-docs/stable/basics.html?highlight=pipe#function-application):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Let f, g, and h be methods that return a ``DataFrame`` object\n",
    ">>> f(g(h(df), arg1=1), arg2=2, arg3=3)\n",
    "```\n",
    "```python\n",
    "# Another version, this time using the pipe() method for explicit definition of data pipelines\n",
    "(df.pipe(h)\n",
    "       .pipe(g, arg1=1)\n",
    "       .pipe(f, arg2=2, arg3=3)\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 References\n",
    "\n",
    "* [VanderPlas, 2015]. VanderPlas, J. *Python Data Science Handbook: Essential Tools for Working with Data*. O'Reilly Media, Aug. 2015.\n",
    "* [McKinney, 2012] McKinney, W. *Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython*. O'Reilly Media, Oct. 2012. **An updated edition of of this book is expected in 2018**.\n",
    "* [Fonnesbeck, 2014] Fonnesbeck, C. *Advanced Statistical Computing* (Bios8366) at Vanderbilt University's Department of Biostatistics. <https://github.com/fonnesbeck/Bios8366/tree/master/>\n",
    "* [Doig, 2016] Doig, C. *Scaling Data Science in Python Tutorial* (notebook 1). Available on GitHub: <https://github.com/chdoig/dss-scaling-tutorial/blob/master/1-Scaling%20Data%20Analysis/1-pandas.ipynb>.\n",
    "* **Modern Pandas (Part 1 - 7)**. Blog series by [Tom Augspurger](http://tomaugspurger.github.io/pages/about.html):\n",
    "    1. http://tomaugspurger.github.io/modern-1.html.\n",
    "    2. http://tomaugspurger.github.io/method-chaining.html.\n",
    "    3. http://tomaugspurger.github.io/modern-3-indexes.html.\n",
    "    4. http://tomaugspurger.github.io/modern-4-performance.html.\n",
    "    5. http://tomaugspurger.github.io/modern-5-tidy.html.\n",
    "    6. http://tomaugspurger.github.io/modern-6-visualization.html.\n",
    "    7. http://tomaugspurger.github.io/modern-7-timeseries.html.\n",
    "\n",
    "\n",
    "- [Augspurger, 2016] Same content by T. Augspurger is available as ***\"Effective Pandas\"***, a [book in PDF](https://leanpub.com/effective-pandas) or a [series of notebooks on GitHub](https://github.com/TomAugspurger/effective-pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
